{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=#6942f5><center>Support Vector Machines</center></font>\n",
    "\n",
    "Support vector machine is a very popular machine learning algorithm that can be effectively used on classification problems as well as on regression ones. The basic concept is dividing binary classified data into two separate spaces and by the side on which the new data lies decides its belonging. There are more ways to do the division, in which we will look into in the moment. But whichever we use, we are still trying to find the best fitted hyperplane (or multiple hyperplanes) that can most effectively classify our data. \n",
    "\n",
    "And what are those support vectors ? When the algo creates the ideal fitted hyperplane in the training data, support vectors are data points that are closest to the hyperplane. The length between the hyperplane and the closest datapoint on each side is called __margin__ - thus we want to fit the hyperplane with the highest margin possible. This is ideal in the nicely divided data which is extremely rare in real life. In most cases you have to count with outliers and a some degree of missclassification. Thus we would like to find the sweet spot in the sensitiveness towards our dataset. For example __maximal margin classifier__ would perform badly with dataset with higher amount of outliers - that is the case generally of course, but due to its principle it applies twice as much here. With this in mind, another very important part is the kernel function used \n",
    "\n",
    "\n",
    "### <font color=#6942f5>Kernel functions</font>\n",
    "\n",
    "Kernel functions decide the way our data is processed. It translates the dataset into the form that will yield us the result we seek. Such mathematical transformations are costly, especially when working with bigger datasets and when diving into more dimensions. So these transofrmations are done through __Kernel trick__ - this allows us to work in the original features space and relieve us the of the calculations in the higher dimensions. Here I will introduce only few often used kernel functions, but there are more and you can even create one yourself:\n",
    "\n",
    "* __Linear Kernel__ - the basic concept with datasets that are lineary separable \n",
    "* __Polynomial Kernel__ - grants additional transformation options to linear kernel function\n",
    "* __Radiabl Basis Function Kernel__ - general purpose gaussian kernel, it is ideal kernel for data we have no prior knowledge\n",
    "* __Sigmoid Kernel__ - this kernel is described as equivalent to a two-layer perceptron neural network\n",
    "\n",
    "\n",
    "### <font color=#6942f5>Parameters</font>\n",
    "\n",
    "there are many parameters with some specific to each individual kernel. Here we will look into 2 basic ones a'nd as always, I would suggest to look into the other parameters when you will start using kernel you never used\n",
    "\n",
    "* __Regularization / C (in Python)__ - optimizes the sensitivity for missclassification. \n",
    " * Lower parameter C yields higher generalization - allows higher missclasification in the training dataset and creates smoother division\n",
    " * Higher parameter C tries to minimize missclassification - visualy creates more comples division, trying to divide almost every datapoint as a result (this can cause overfitting)\n",
    "\n",
    "\n",
    "* __Gamma__ - defines how many data points will be considered when learning the model\n",
    " * Lower gamma allows further data points from the hyperplane to participate in the learning of the model\n",
    " * Higher gamma allows only the closest data points to participate in the learning of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color=#6942f5><center>lets dive into code - classifier</center></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.52101</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1.10</td>\n",
       "      <td>71.78</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        RI     Na    Mg    Al     Si     K    Ca   Ba   Fe  Type\n",
       "0  1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.0  0.0     1\n",
       "1  1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.0  0.0     1\n",
       "2  1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.0  0.0     1\n",
       "3  1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.0  0.0     1\n",
       "4  1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.0  0.0     1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_path = \".jupyter\\\\datasets\\\\raw\\\\\"\n",
    "glass_df = pd.read_csv(datasets_path + \"glass.csv\")\n",
    "\n",
    "glass_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 5, 6, 7], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glass_df[\"Type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 214 entries, 0 to 213\n",
      "Data columns (total 10 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   RI      214 non-null    float64\n",
      " 1   Na      214 non-null    float64\n",
      " 2   Mg      214 non-null    float64\n",
      " 3   Al      214 non-null    float64\n",
      " 4   Si      214 non-null    float64\n",
      " 5   K       214 non-null    float64\n",
      " 6   Ca      214 non-null    float64\n",
      " 7   Ba      214 non-null    float64\n",
      " 8   Fe      214 non-null    float64\n",
      " 9   Type    214 non-null    int64  \n",
      "dtypes: float64(9), int64(1)\n",
      "memory usage: 16.8 KB\n"
     ]
    }
   ],
   "source": [
    "glass_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have dataset with 6 specific glass types (we just want to build SVM model so we dont need to know which number represents which type, just numbers will do in our case) and composition of each measurement. We will try to test each kernel function with little tweak in the parameters we discussed above and lets see what we can do here. This is very small dataset, where our SVM model could perform well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train size : (171, 9), X_test size: (43, 9)\n"
     ]
    }
   ],
   "source": [
    "X = glass_df[[\"RI\", \"Na\", \"Mg\", \"Al\", \"Si\", \"K\", \"Ca\", \"Ba\", \"Fe\"]] # I prefer explicit selecting to avoid mistakes than slicing\n",
    "y = glass_df[\"Type\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "print(\"X_train size : \" + str(X_train.shape) + \", X_test size: \" + str(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, we prepared our training and testing data, lets create a loop where we will test kernels and parameters, it will create a lengtly list, but this kind of testing is a good start on our way off understanding how the parameters impact the models overall performence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing SVC with linear kernel:\n",
      "   Parameter C set to 0.1\n",
      "      gamma set to:\t 0.1\t score:      0.488\n",
      "      gamma set to:\t 0.5\t score:      0.488\n",
      "      gamma set to:\t 1\t score:      0.488\n",
      "      gamma set to:\t 5\t score:      0.488\n",
      "   Parameter C set to 0.5\n",
      "      gamma set to:\t 0.1\t score:      0.674\n",
      "      gamma set to:\t 0.5\t score:      0.674\n",
      "      gamma set to:\t 1\t score:      0.674\n",
      "      gamma set to:\t 5\t score:      0.674\n",
      "   Parameter C set to 1\n",
      "      gamma set to:\t 0.1\t score:      0.628\n",
      "      gamma set to:\t 0.5\t score:      0.628\n",
      "      gamma set to:\t 1\t score:      0.628\n",
      "      gamma set to:\t 5\t score:      0.628\n",
      "   Parameter C set to 5\n",
      "      gamma set to:\t 0.1\t score:      0.651\n",
      "      gamma set to:\t 0.5\t score:      0.651\n",
      "      gamma set to:\t 1\t score:      0.651\n",
      "      gamma set to:\t 5\t score:      0.651\n",
      "\n",
      "Testing SVC with poly kernel:\n",
      "   Parameter C set to 0.1\n",
      "      gamma set to:\t 0.1\t score:      0.628\n",
      "      gamma set to:\t 0.5\t score:      0.674\n",
      "      gamma set to:\t 1\t score:      0.721\n",
      "      gamma set to:\t 5\t score:      0.651\n",
      "   Parameter C set to 0.5\n",
      "      gamma set to:\t 0.1\t score:      0.651\n",
      "      gamma set to:\t 0.5\t score:      0.721\n",
      "      gamma set to:\t 1\t score:      0.674\n",
      "      gamma set to:\t 5\t score:      0.651\n",
      "   Parameter C set to 1\n",
      "      gamma set to:\t 0.1\t score:      0.628\n",
      "      gamma set to:\t 0.5\t score:      0.698\n",
      "      gamma set to:\t 1\t score:      0.674\n",
      "      gamma set to:\t 5\t score:      0.651\n",
      "   Parameter C set to 5\n",
      "      gamma set to:\t 0.1\t score:      0.628\n",
      "      gamma set to:\t 0.5\t score:      0.721\n",
      "      gamma set to:\t 1\t score:      0.674\n",
      "      gamma set to:\t 5\t score:      0.581\n",
      "\n",
      "Testing SVC with rbf kernel:\n",
      "   Parameter C set to 0.1\n",
      "      gamma set to:\t 0.1\t score:      0.442\n",
      "      gamma set to:\t 0.5\t score:      0.488\n",
      "      gamma set to:\t 1\t score:      0.465\n",
      "      gamma set to:\t 5\t score:      0.488\n",
      "   Parameter C set to 0.5\n",
      "      gamma set to:\t 0.1\t score:      0.558\n",
      "      gamma set to:\t 0.5\t score:      0.698\n",
      "      gamma set to:\t 1\t score:      0.698\n",
      "      gamma set to:\t 5\t score:      0.628\n",
      "   Parameter C set to 1\n",
      "      gamma set to:\t 0.1\t score:      0.581\n",
      "      gamma set to:\t 0.5\t score:      0.744\n",
      "      gamma set to:\t 1\t score:      0.674\n",
      "      gamma set to:\t 5\t score:      0.651\n",
      "   Parameter C set to 5\n",
      "      gamma set to:\t 0.1\t score:      0.721\n",
      "      gamma set to:\t 0.5\t score:      0.674\n",
      "      gamma set to:\t 1\t score:      0.721\n",
      "      gamma set to:\t 5\t score:      0.628\n",
      "\n",
      "Testing SVC with sigmoid kernel:\n",
      "   Parameter C set to 0.1\n",
      "      gamma set to:\t 0.1\t score:      0.395\n",
      "      gamma set to:\t 0.5\t score:      0.395\n",
      "      gamma set to:\t 1\t score:      0.395\n",
      "      gamma set to:\t 5\t score:      0.395\n",
      "   Parameter C set to 0.5\n",
      "      gamma set to:\t 0.1\t score:      0.395\n",
      "      gamma set to:\t 0.5\t score:      0.395\n",
      "      gamma set to:\t 1\t score:      0.395\n",
      "      gamma set to:\t 5\t score:      0.395\n",
      "   Parameter C set to 1\n",
      "      gamma set to:\t 0.1\t score:      0.395\n",
      "      gamma set to:\t 0.5\t score:      0.395\n",
      "      gamma set to:\t 1\t score:      0.395\n",
      "      gamma set to:\t 5\t score:      0.395\n",
      "   Parameter C set to 5\n",
      "      gamma set to:\t 0.1\t score:      0.395\n",
      "      gamma set to:\t 0.5\t score:      0.395\n",
      "      gamma set to:\t 1\t score:      0.395\n",
      "      gamma set to:\t 5\t score:      0.395\n"
     ]
    }
   ],
   "source": [
    "# here we will create loop, which will create SVM model with kernels and parameters mentioned above\n",
    "kernels = [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]\n",
    "param = [0.1, 0.5, 1, 5] # I will use the same scale for C and for gamma\n",
    "\n",
    "model = svm.SVC()\n",
    "for i in range(len(kernels)):\n",
    "    model.kernel = kernels[i]\n",
    "    print(\"\\nTesting SVC with \" + model.kernel + \" kernel:\")\n",
    "    for j in range(len(param)):\n",
    "        model.C = param[j]\n",
    "        print(\"   Parameter C set to \" + str(model.C))\n",
    "        for k in range(len(param)):\n",
    "            model.gamma = param[k]\n",
    "            model.fit(X_train, y_train)\n",
    "            score = model.score(X_test, y_test)\n",
    "            print(\"      gamma set to:\\t \" + str(model.gamma) + \"\\t score: \" + str(\"{:10.3f}\".format(score)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "If we would run this notebook multiple times, we would get variety of results, depending on the train test split, especialy on small datasets like this. Even though this is a valid way to test your model, there is always some data lost with this way of testing, thats where cross validation can help\n",
    "\n",
    "##### <font color=#6942f5>cross validation</font>\n",
    "\n",
    "Cross validation is similar to train_test_split function, but it divides the dataset into n parts and then it run loops, training and testing with each individual part as testing data, we can then mean the values we get back in a list to get the final/average score. This way we are using every data point in the DataFrame. As a drawback, this function is much more computationaly demanding against the split function used above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets create a function that will run the cross validation on model with specified kernel function and params to loop with, then we will se how different our scores will be. I will try to specify parameters for each kernel according to final results above, if we can get higher score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing SVC with linear kernel:\n",
      "   Parameter C set to 0.5\n",
      "      gamma set to:\t 0.5\t score:      0.585\n",
      "      gamma set to:\t 1\t score:      0.585\n",
      "      gamma set to:\t 5\t score:      0.585\n",
      "      gamma set to:\t 15\t score:      0.585\n",
      "   Parameter C set to 1\n",
      "      gamma set to:\t 0.5\t score:      0.589\n",
      "      gamma set to:\t 1\t score:      0.589\n",
      "      gamma set to:\t 5\t score:      0.589\n",
      "      gamma set to:\t 15\t score:      0.589\n",
      "   Parameter C set to 3\n",
      "      gamma set to:\t 0.5\t score:      0.622\n",
      "      gamma set to:\t 1\t score:      0.622\n",
      "      gamma set to:\t 5\t score:      0.622\n",
      "      gamma set to:\t 15\t score:      0.622\n",
      "   Parameter C set to 5\n",
      "      gamma set to:\t 0.5\t score:      0.608\n",
      "      gamma set to:\t 1\t score:      0.608\n",
      "      gamma set to:\t 5\t score:      0.608\n",
      "      gamma set to:\t 15\t score:      0.608\n",
      "   Parameter C set to 10\n",
      "      gamma set to:\t 0.5\t score:      0.603\n",
      "      gamma set to:\t 1\t score:      0.603\n",
      "      gamma set to:\t 5\t score:      0.603\n",
      "      gamma set to:\t 15\t score:      0.603\n",
      "\n",
      "Testing SVC with poly kernel:\n",
      "   Parameter C set to 0.01\n",
      "      gamma set to:\t 0.1\t score:      0.608\n",
      "      gamma set to:\t 0.3\t score:      0.575\n",
      "      gamma set to:\t 0.7\t score:      0.552\n",
      "      gamma set to:\t 1\t score:      0.557\n",
      "      gamma set to:\t 3\t score:      0.557\n",
      "   Parameter C set to 0.1\n",
      "      gamma set to:\t 0.1\t score:      0.566\n",
      "      gamma set to:\t 0.3\t score:      0.608\n",
      "      gamma set to:\t 0.7\t score:      0.566\n",
      "      gamma set to:\t 1\t score:      0.571\n",
      "      gamma set to:\t 3\t score:      0.557\n",
      "   Parameter C set to 0.3\n",
      "      gamma set to:\t 0.1\t score:      0.599\n",
      "      gamma set to:\t 0.3\t score:      0.617\n",
      "      gamma set to:\t 0.7\t score:      0.594\n",
      "      gamma set to:\t 1\t score:      0.566\n",
      "      gamma set to:\t 3\t score:      0.552\n",
      "   Parameter C set to 0.7\n",
      "      gamma set to:\t 0.1\t score:      0.589\n",
      "      gamma set to:\t 0.3\t score:      0.599\n",
      "      gamma set to:\t 0.7\t score:      0.585\n",
      "      gamma set to:\t 1\t score:      0.566\n",
      "      gamma set to:\t 3\t score:      0.566\n",
      "   Parameter C set to 1\n",
      "      gamma set to:\t 0.1\t score:      0.599\n",
      "      gamma set to:\t 0.3\t score:      0.585\n",
      "      gamma set to:\t 0.7\t score:      0.590\n",
      "      gamma set to:\t 1\t score:      0.585\n",
      "      gamma set to:\t 3\t score:      0.557\n",
      "   Parameter C set to 10\n",
      "      gamma set to:\t 0.1\t score:      0.594\n",
      "      gamma set to:\t 0.3\t score:      0.589\n",
      "      gamma set to:\t 0.7\t score:      0.590\n",
      "      gamma set to:\t 1\t score:      0.562\n",
      "      gamma set to:\t 3\t score:      0.552\n",
      "   Parameter C set to 20\n",
      "      gamma set to:\t 0.1\t score:      0.589\n",
      "      gamma set to:\t 0.3\t score:      0.589\n",
      "      gamma set to:\t 0.7\t score:      0.575\n",
      "      gamma set to:\t 1\t score:      0.580\n",
      "      gamma set to:\t 3\t score:      0.552\n",
      "\n",
      "Testing SVC with rbf kernel:\n",
      "   Parameter C set to 0.5\n",
      "      gamma set to:\t 0.05\t score:      0.534\n",
      "      gamma set to:\t 0.2\t score:      0.599\n",
      "      gamma set to:\t 0.5\t score:      0.622\n",
      "      gamma set to:\t 1\t score:      0.627\n",
      "      gamma set to:\t 3\t score:      0.514\n",
      "   Parameter C set to 1\n",
      "      gamma set to:\t 0.05\t score:      0.567\n",
      "      gamma set to:\t 0.2\t score:      0.641\n",
      "      gamma set to:\t 0.5\t score:      0.660\n",
      "      gamma set to:\t 1\t score:      0.660\n",
      "      gamma set to:\t 3\t score:      0.622\n",
      "   Parameter C set to 5\n",
      "      gamma set to:\t 0.05\t score:      0.650\n",
      "      gamma set to:\t 0.2\t score:      0.669\n",
      "      gamma set to:\t 0.5\t score:      0.692\n",
      "      gamma set to:\t 1\t score:      0.688\n",
      "      gamma set to:\t 3\t score:      0.636\n",
      "   Parameter C set to 10\n",
      "      gamma set to:\t 0.05\t score:      0.650\n",
      "      gamma set to:\t 0.2\t score:      0.659\n",
      "      gamma set to:\t 0.5\t score:      0.701\n",
      "      gamma set to:\t 1\t score:      0.678\n",
      "      gamma set to:\t 3\t score:      0.617\n",
      "   Parameter C set to 20\n",
      "      gamma set to:\t 0.05\t score:      0.664\n",
      "      gamma set to:\t 0.2\t score:      0.683\n",
      "      gamma set to:\t 0.5\t score:      0.687\n",
      "      gamma set to:\t 1\t score:      0.664\n",
      "      gamma set to:\t 3\t score:      0.622\n",
      "   Parameter C set to 40\n",
      "      gamma set to:\t 0.05\t score:      0.659\n",
      "      gamma set to:\t 0.2\t score:      0.692\n",
      "      gamma set to:\t 0.5\t score:      0.682\n",
      "      gamma set to:\t 1\t score:      0.683\n",
      "      gamma set to:\t 3\t score:      0.589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def test_model (model, params_C, params_gamma, X, y):\n",
    "    print(\"Testing SVC with \" + model.kernel + \" kernel:\")\n",
    "    for i in range(len(params_C)):\n",
    "        model.C = params_C[i]\n",
    "        print(\"   Parameter C set to \" + str(model.C))\n",
    "        for j in range(len(params_gamma)):\n",
    "            model.gamma = params_gamma[j]\n",
    "            score = cross_val_score(model, X, y, cv=4)\n",
    "            print(\"      gamma set to:\\t \" + str(model.gamma) + \"\\t score: \" + str(\"{:10.3f}\".format(score.mean())))\n",
    "    print()\n",
    "\n",
    "# linear kernel\n",
    "param_lin_C = [0.5, 1, 3, 5, 10]\n",
    "param_lin_gamma = [0.5, 1, 5, 15]\n",
    "lin_model = svm.SVC(kernel=\"linear\")\n",
    "test_model(lin_model, param_lin_C, param_lin_gamma, X, y)\n",
    "\n",
    "# polynomial kernel\n",
    "param_poly_C = [0.01, 0.1, 0.3, 0.7, 1, 10, 20]\n",
    "param_poly_gamma = [0.1, 0.3, 0.7, 1, 3]\n",
    "poly_model = svm.SVC(kernel=\"poly\")\n",
    "test_model(poly_model, param_poly_C, param_poly_gamma, X, y)\n",
    "\n",
    "# rbf kernel\n",
    "param_rbf_C = [0.5, 1, 5, 10, 20, 40]\n",
    "param_rbf_gamma = [0.05, 0.2, 0.5, 1, 3]\n",
    "rbf_model = svm.SVC(kernel=\"rbf\")\n",
    "test_model(rbf_model, param_rbf_C, param_rbf_gamma, X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, just by eyeing through both cells you can see that cross validation us smoother. I tested my patience and run the notebook few times just to confirm for myself - standard split had various results, sometimes even pretty high differences, but cross validation performed the same. Its obvious due to the math behind it, but you know that feeling, you know it, but still have to test it anyway ! This way you can test your way to the best fitted model you can find. You are never experienced enough to just rely on the first model you create and go on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=#6942f5><center>Final words</center></font>\n",
    "Already ? Yea, already, just 8 code cells, thats my new record ! ... I just wanted to point out the basic concept behind the SVM and we used the classifier version + we tried 2 ways to validate our model. When I will find the time, I will come back and add some more models - other than classifier. But for now thats all and as always, big thanks to anybody who took the time to read through this notebook ! Have a great day !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
